{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himanshu911/Unsupervised-Aspect-Extraction/blob/main/ABAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj-uU82FUolw"
      },
      "source": [
        "#An Unsupervised Neural Attention Model for Aspect Extraction\n",
        "\n",
        "Implementation of https://www.comp.nus.edu.sg/~leews/publications/acl17.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6uzbO36DSE5"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVWU9dqWESXJ",
        "outputId": "fd0f7688-21fa-462d-f969-6ca1a329889a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import pdb\n",
        "import spacy\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from gensim.models import FastText\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from fastai.text import *\n",
        "from fastai.text.data import _join_texts\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "print(f'fastai version: {__version__}')\n",
        "print(f'torch version: {torch.__version__}')\n",
        "print(f'spacy version: {spacy.__version__}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fastai version: 1.0.57\n",
            "torch version: 1.1.0\n",
            "spacy version: 2.1.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL7DDUeePR2d"
      },
      "source": [
        "# import fastai.utils.collect_env\n",
        "# fastai.utils.collect_env.show_install()\n",
        "\n",
        "torch.cuda.set_device(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wnuhWyUWGOH"
      },
      "source": [
        "## Citysearch corpus\n",
        "This is a **restaurant review corpus** which contains over 50,000 restaurant reviews from Citysearch New York. There are **6 manually defined aspect labels:**\n",
        "\n",
        "*Food, Staff, Ambience, Price, Anecdotes, and Miscellaneous*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeuG2cY6EUz9",
        "outputId": "8eed78f7-5e47-4614-b1cd-ea587e32d644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVX2MpyaEaxd",
        "outputId": "86a322d4-b500-467a-fd29-c4b0dd7ed27c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!unzip 'gdrive/My Drive/Data/datasets.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  gdrive/My Drive/Data/datasets.zip\n",
            "   creating: datasets/\n",
            "  inflating: datasets/.DS_Store      \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/datasets/\n",
            "  inflating: __MACOSX/datasets/._.DS_Store  \n",
            "   creating: datasets/beer/\n",
            "  inflating: datasets/beer/test.txt  \n",
            "  inflating: datasets/beer/test_label.txt  \n",
            "  inflating: datasets/beer/train.txt  \n",
            "   creating: datasets/restaurant/\n",
            "  inflating: datasets/restaurant/test.txt  \n",
            "  inflating: datasets/restaurant/test_label.txt  \n",
            "  inflating: datasets/restaurant/train.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jowud5Y4H1ms"
      },
      "source": [
        "data_dir = 'datasets/'\n",
        "domain = 'restaurant/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBgy_cWEpqxg"
      },
      "source": [
        "def load_dataset(filename):\n",
        "  f = open(data_dir + domain + filename+'.txt', 'r', encoding='utf-8')\n",
        "\n",
        "  print(filename)\n",
        "  all_reviews = f.readlines()\n",
        "  print('Total Reviews: ', len(all_reviews))\n",
        "  f.close()\n",
        "\n",
        "  sentences = []\n",
        "  for i,review in enumerate(all_reviews):\n",
        "      sentences.append(review.strip('\\n'))\n",
        "\n",
        "  col = 'labels' if filename=='test_label' else 'text_org'\n",
        "\n",
        "  df = pd.DataFrame({col:sentences})\n",
        "  df.to_csv(data_dir + domain + filename+'.csv', encoding='utf-8', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ_2m39lqMvd",
        "outputId": "bbddb537-e7f4-4529-f47c-454c70978f8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "load_dataset('train')\n",
        "load_dataset('test')\n",
        "load_dataset('test_label')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "Total Reviews:  281989\n",
            "test\n",
            "Total Reviews:  3328\n",
            "test_label\n",
            "Total Reviews:  3328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO3EuJA-rPzw"
      },
      "source": [
        "df_train = pd.read_csv(data_dir + domain + 'train.csv', encoding='utf-8')\n",
        "df_train = df_train[df_train.text_org.notnull()]\n",
        "\n",
        "df_valid = pd.read_csv(data_dir + domain + 'test.csv', encoding='utf-8')\n",
        "df_valid = df_valid[df_valid.text_org.notnull()]\n",
        "\n",
        "df_label = pd.read_csv(data_dir + domain + 'test_label.csv', encoding='utf-8')\n",
        "df_label = df_label[df_label.labels.notnull()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGByb3lHUupw",
        "outputId": "8473f4a5-b8da-405e-f62d-b5d6cc4d3fe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_train.shape, df_valid.shape, df_label.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((281645, 1), (3328, 1), (3328, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Os-DxesFyDT"
      },
      "source": [
        "df_train['label'] = 'NA'\n",
        "df_valid['label'] = df_label.labels.values\n",
        "\n",
        "df_train['is_valid'] = False\n",
        "df_valid['is_valid'] = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSl1Gwtihox3"
      },
      "source": [
        "df = df_train.append(df_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "8a778b7f-e4d0-4597-83dc-f3fab2867373",
        "id": "vlJ6XAe3s9CR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284973, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4m4AH5bhJ9t",
        "outputId": "40a32cf0-8f04-4061-a0fa-33c045252c8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_org</th>\n",
              "      <th>label</th>\n",
              "      <th>is_valid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What do I like about Jeollado? I like the 2 for 1 rolls (sometimes 3 for 1) the prices and the variety on the menu</td>\n",
              "      <td>NA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What don't I like? The rolls are tiny so you have to order more anyway and they will often get your order wrong if you stray from the menu</td>\n",
              "      <td>NA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>For the money, it's a dependable and fun place to get sushi - bring friends and share the 2 for 1 rolls (they have to be 2 of the same</td>\n",
              "      <td>NA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>)</td>\n",
              "      <td>NA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This place is a great deal for the price and the food they give you</td>\n",
              "      <td>NA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                     text_org  ... is_valid\n",
              "0  What do I like about Jeollado? I like the 2 for 1 rolls (sometimes 3 for 1) the prices and the variety on the menu                          ...  False  \n",
              "1  What don't I like? The rolls are tiny so you have to order more anyway and they will often get your order wrong if you stray from the menu  ...  False  \n",
              "2  For the money, it's a dependable and fun place to get sushi - bring friends and share the 2 for 1 rolls (they have to be 2 of the same      ...  False  \n",
              "3  )                                                                                                                                           ...  False  \n",
              "4  This place is a great deal for the price and the food they give you                                                                         ...  False  \n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsXKM195i7X8"
      },
      "source": [
        "##Preprocessing\n",
        "\n",
        "The text is lower-cased and lemmatized. Punctuations and numbers are removed. Symbols like **$** are preserved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6fym6f_rP9T"
      },
      "source": [
        "nlp = spacy.blank('en', disable=[\"parser\", 'tagger', \"ner\"])\n",
        "df['text'] = df['text_org'].apply(lambda x: ' '.join([tok.text for tok in nlp(x)\n",
        "              if ((tok.lemma_ != '-PRON-') & (tok.like_num == False) & (tok.is_stop == False) & (tok.is_punct == False) & (tok.is_space == False))]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKG2d7Csi6oj"
      },
      "source": [
        "df.loc[df.text.str.len() == 0, 'text'] = 'miscellaneous'\n",
        "df = df[~((df.is_valid==False) & (df.text=='miscellaneous'))].copy()\n",
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYG0YyZduO3t",
        "outputId": "2a7906c6-90d9-4120-aab5-b744c8790220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_org</th>\n",
              "      <th>label</th>\n",
              "      <th>is_valid</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>282324</th>\n",
              "      <td>Was there Friday night .</td>\n",
              "      <td>Anecdotes</td>\n",
              "      <td>True</td>\n",
              "      <td>Friday night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282325</th>\n",
              "      <td>Best Pastrami I ever had and great portion without being ridiculous .</td>\n",
              "      <td>Food</td>\n",
              "      <td>True</td>\n",
              "      <td>Best Pastrami great portion ridiculous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282326</th>\n",
              "      <td>And I 've been to many NYC delis .</td>\n",
              "      <td>Anecdotes</td>\n",
              "      <td>True</td>\n",
              "      <td>ve NYC delis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282327</th>\n",
              "      <td>My wife had the fried shrimp which are huge and loved it .</td>\n",
              "      <td>Food</td>\n",
              "      <td>True</td>\n",
              "      <td>wife fried shrimp huge loved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282328</th>\n",
              "      <td>Price no more than a Jersey deli but way better .</td>\n",
              "      <td>Price</td>\n",
              "      <td>True</td>\n",
              "      <td>Price Jersey deli way better</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                       text_org  ...                                    text\n",
              "282324   Was there Friday night .                                                ...  Friday night                          \n",
              "282325   Best Pastrami I ever had and great portion without being ridiculous .   ...  Best Pastrami great portion ridiculous\n",
              "282326   And I 've been to many NYC delis .                                      ...  ve NYC delis                          \n",
              "282327   My wife had the fried shrimp which are huge and loved it .              ...  wife fried shrimp huge loved          \n",
              "282328   Price no more than a Jersey deli but way better .                       ...  Price Jersey deli way better          \n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap5h8mWdEkQE",
        "outputId": "09297048-1306-4259-a66c-d5a043125afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(282329, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOHIx-UbkGuQ",
        "outputId": "df449abf-3dca-44dc-fbac-69329b1af09a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "classes = df['label'].unique()\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NA', 'Food Ambience', 'Staff', 'Ambience', 'Miscellaneous', 'Anecdotes', 'Staff Ambience', 'Food Staff',\n",
              "       'Food', 'Staff Anecdotes', 'Ambience Miscellaneous', 'Price', 'Food Price', 'Food Miscellaneous', 'Price Staff',\n",
              "       'Anecdotes Miscellaneous', 'Food Anecdotes', 'Price Miscellaneous', 'Price Ambience', 'Ambience Anecdotes',\n",
              "       'Price Anecdotes', 'Positive', 'Staff Miscellaneous', 'Neutral'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKvfeCqJkPaU"
      },
      "source": [
        "##Custom Fastai pipeline\n",
        "\n",
        "Creating Databunch object that wraps that is used inside Learner object to train a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIEqnmK0tf6Y"
      },
      "source": [
        "EMB_DIM = 300\n",
        "NUM_ASP = 14\n",
        "MAX_VOCAB_SIZE = 60000\n",
        "PAD_IDX = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK2rokFwtxuw"
      },
      "source": [
        "class CustomTokenizer(SpacyTokenizer):\n",
        "    def __init__(self, lang:str):\n",
        "        self.tok = spacy.blank(lang, disable=[\"parser\", 'tagger', \"ner\"])\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        doc = self.tok.tokenizer(t)\n",
        "        tokens = [tok.lemma_.lower().strip() for tok in doc\n",
        "              if ((tok.lemma_ != '-PRON-') & (tok.like_num == False) & (tok.is_stop == False) & (tok.is_punct == False) & (tok.is_space == False))]\n",
        "        if (len(tokens)==0):\n",
        "          tokens = ['miscellaneous']\n",
        "        return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyW8q2pUjgc3"
      },
      "source": [
        "class CustomTokenizeProcessor(TokenizeProcessor):\n",
        "  def process(self, ds):\n",
        "      ds.items = _join_texts(ds.inner_df[ds.cols].values, (len(ds.cols) > 1), self.include_bos, self.include_eos)\n",
        "      tokens = []\n",
        "      for i in progress_bar(range(0,len(ds),self.chunksize), leave=False):\n",
        "          tokens += self.tokenizer.process_all(ds.items[i:i+self.chunksize])\n",
        "      ds.items = tokens\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yWpXdrW7ArE"
      },
      "source": [
        "class CustomNumericalizeProcessor(NumericalizeProcessor):\n",
        "  def process(self, ds):\n",
        "        if self.vocab is None: self.vocab = Vocab.create(ds.items, self.max_vocab, self.min_freq)\n",
        "        ds.vocab = self.vocab\n",
        "        super().process(ds)\n",
        "        ds.preprocessed = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13XpOHG2vGKt"
      },
      "source": [
        "  class CustomTextList(TextList):\n",
        "\n",
        "    def __init__(self, items:Iterator, vocab:Vocab=None, pad_idx:int=1, cols=None, **kwargs):\n",
        "        super().__init__(items, **kwargs)\n",
        "        self.vocab,self.pad_idx = vocab,pad_idx\n",
        "        self.cols=cols\n",
        "        self.copy_new += ['cols', 'vocab', 'pad_idx']\n",
        "        self.preprocessed = False\n",
        "\n",
        "    # defines how to construct an ItemBase from the data in the ItemList.items array\n",
        "    def get(self, i):\n",
        "        if not self.preprocessed:\n",
        "            return self.inner_df.iloc[i][self.cols] if hasattr(self, 'inner_df') else self.items[i]\n",
        "\n",
        "        item = self.items[i]\n",
        "#         return item\n",
        "        return Text(item, self.vocab.textify(item))\n",
        "\n",
        "    def get_len(self, i):\n",
        "        if not self.preprocessed:\n",
        "            return len(self.inner_df.iloc[i][self.cols]) if hasattr(self, 'inner_df') else len(self.items[i])\n",
        "\n",
        "        item = self.items[i]\n",
        "        return len(item)\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def from_df(cls, df:DataFrame, cols=None, processor:PreProcessor=None, vocab:Vocab=None, max_vocab=MAX_VOCAB_SIZE,\n",
        "                     tok_func=None, **kwargs) -> 'TextList':\n",
        "        processor = ifnone(processor, [CustomTokenizeProcessor(tokenizer=Tokenizer(tok_func=tok_func), include_bos=False, include_eos=False), CustomNumericalizeProcessor(vocab=vocab)])\n",
        "        return cls(items=range(len(df)), cols=cols, processor=processor, vocab=vocab, inner_df=df, **kwargs)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNYdDteRRwa8"
      },
      "source": [
        "tl1 = CustomTextList.from_df(df, path=data_dir+domain, cols=['text'], tok_func=CustomTokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_vYjo2yMFDA"
      },
      "source": [
        "ils = tl1.split_from_df(col='is_valid')\n",
        "lls = ils.label_from_df('label', classes=classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4fVXpveMuKu"
      },
      "source": [
        "data = lls.databunch(bs=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Nc-Hwksp3VP"
      },
      "source": [
        "vocab = data.train_ds.vocab\n",
        "VOCAB_SIZE = len(vocab.itos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lguBUeHoMX_r",
        "outputId": "f626cbb6-c191-4eef-9373-2c7ec5a634b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "data.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>issue babbo dinner reservation month advance thursday dinner nonetheless host hostess curt rude room wait bar limit seat stand diner waiters hosts enamor fact xxunk xxunk mom xxunk xxunk dine upstairs temperature hot stuffy request downstairs seat instead cool music terrible loud raucous irritate play nirvana loud highly unusual inappropriate place nice babbo compliments babbo bartenders know stuff recommend good wine bus boy good fill water glass provide bread offer</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>dare tourist trap french japanese restaurant take like xxunk airplane serve crass rude nasty snobby waiter speak western language truly vile waste money yes nice view view vastly cheap price tourist trip manhattan need pretentious awful snobby xxunk place xxunk earn dollar place strictly boycott hire polite staff maitre have hire chef well xxunk city special currently xxunk miss account</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>smoke oyster divine devil egg okay little xxunk shell kansas city ribs apple smoked chicken- deliciously xxunk rib fall bone messy banana cream pie bread pudding bread pudding well had- perfect combo custard cinammon little caramel flavor</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>good house salad xxunk green tofu skin tasty sake marinate sea bass heavenly sake selection well see city sake sommelier taka sure cute sashimi par nobu bond street fraction cost morsel fish eat melt mouth</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>com xxunk turn frankfurter aficionado brian xxunk stuff niman ranch hickory smoke xxunk antibiotic free beef dog oversized fresh bake bun insanely good homemade condiment cube pickle chili relish molasses mustard couple buck</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIggPeGOmrnX"
      },
      "source": [
        "##FastText\n",
        "\n",
        "A **skipgram model** trained on the Citysearch corpus to generate 300 dimensional word embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipnyt7p-lznq"
      },
      "source": [
        "# def createVectors(df, emb_dim):\n",
        "#   nlp = spacy.blank('en', disable=[\"parser\", 'tagger', \"ner\"])\n",
        "#   reviews = df.text.tolist()\n",
        "#   sentences = []\n",
        "#   for review in reviews:\n",
        "#     tokens = [tok.text.lower().strip() for tok in nlp.tokenizer(review) if ((tok.is_space == False) & (tok.is_punct == False))]\n",
        "#     sentences.append(tokens)\n",
        "\n",
        "#   model = FastText(sentences, size=emb_dim, window=10, min_count=4, negative=20, workers=4, sg=1, iter=20)\n",
        "#   model.save(data_dir+domain + 'FT_SG_model')\n",
        "\n",
        "#   return model\n",
        "\n",
        "# ft_model = createVectors(df, EMB_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DDhZVI8DwbB",
        "outputId": "dcbf6de8-ca27-4386-d127-ff850c605467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "ft_model = FastText.load('gdrive/My Drive/Data/FT_SG_model')\n",
        "kv = ft_model.wv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBuueZY577Yn",
        "outputId": "a19d625b-24da-4217-afa8-90f8d3f428b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('FastText vocab length: ', len(kv.vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FastText vocab length:  17556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Le1GEx2ko6wd"
      },
      "source": [
        "##Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_ECLSElDRsJ"
      },
      "source": [
        "class ABAE(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, emb_dim, norm_emb_matrix, norm_aspect_matrix, num_aspects, neg_size, reg):\n",
        "\n",
        "      super().__init__()\n",
        "\n",
        "      self.vocab_size = vocab_size\n",
        "      self.emb_dim = emb_dim\n",
        "      self.K = num_aspects\n",
        "      self.neg_size = neg_size\n",
        "      self.reg = reg\n",
        "\n",
        "      self.E = nn.Embedding(vocab_size, emb_dim, padding_idx = 1) #word embeddings\n",
        "      self.E.weight.data.copy_(torch.from_numpy(norm_emb_matrix))\n",
        "      self.E.weight.requires_grad = False\n",
        "\n",
        "      #self.A = nn.Embedding(K, emb_dim) #aspect_emb\n",
        "      self.A = nn.Parameter(torch.from_numpy(norm_aspect_matrix))\n",
        "\n",
        "      self.M = nn.Parameter(torch.rand(emb_dim, emb_dim))\n",
        "      self.L = nn.Linear(emb_dim, num_aspects)\n",
        "      self.register_buffer('identity_mat', torch.eye(num_aspects))\n",
        "\n",
        "    def forward(self, xb):\n",
        "\n",
        "      b_size = xb.shape[0]\n",
        "      seq_len = xb.shape[1]\n",
        "\n",
        "      e_w = self.E(xb)\n",
        "      y_s = torch.div(torch.sum(e_w, dim=1), torch.sum(e_w!=0.0, dim=1, dtype=torch.float32)) #avg(e_w), (batch x dim)\n",
        "\n",
        "      y = torch.t(torch.mm(self.M,torch.t(y_s)))#(batch x dim)\n",
        "      y = y.unsqueeze(dim=1).expand(b_size, seq_len, self.emb_dim)#(batch x seq_len x dim)\n",
        "\n",
        "      d = torch.sum(e_w * y, dim=2)#(batch x seq_len)\n",
        "      attn_wts_org = F.softmax(d, dim=1)#(batch x seq_len)\n",
        "\n",
        "      attn_wts = attn_wts_org.unsqueeze(dim=2).expand(b_size, seq_len, self.emb_dim)#(batch x seq_len x dim)\n",
        "      z_s = torch.sum(e_w * attn_wts, dim = 1)#(batch x dim)\n",
        "\n",
        "\n",
        "      neg_idxs = torch.randint(high=b_size, size=(b_size, self.neg_size), dtype=torch.int64).tolist()\n",
        "      neg_idxs = [[x if x!= i else (i-1)%(b_size-1) for x in lst] for (i, lst) in enumerate(neg_idxs)]\n",
        "\n",
        "      neg_sentences = self.E(xb[torch.LongTensor(neg_idxs)])\n",
        "      z_n = torch.div(torch.sum(neg_sentences, dim=2),torch.sum(neg_sentences!=0.0, dim=2, dtype=torch.float32))\n",
        "\n",
        "      p_t = self.L(z_s)\n",
        "      p_t = F.softmax(p_t, dim=1)#(batch x num_aspects)\n",
        "\n",
        "      r_s = torch.mm(p_t, self.A)#(batch x dim)\n",
        "\n",
        "      r_s = F.normalize(r_s, p=2, dim=-1)\n",
        "      z_s = F.normalize(z_s, p=2, dim=-1)\n",
        "      z_n = F.normalize(z_n, p=2, dim=-1)\n",
        "\n",
        "      pos = torch.sum(r_s * z_s, dim=-1, keepdim=True).unsqueeze(dim=1).expand(b_size, self.neg_size, 1)#(batch x neg_size, 1)\n",
        "      r_s = r_s.unsqueeze(dim=1).expand(b_size, self.neg_size, self.emb_dim)#(batch x neg_size x dim)\n",
        "      neg = torch.sum(r_s * z_n, dim=-1, keepdim=True)\n",
        "\n",
        "      loss = torch.sum(torch.max(torch.zeros_like(neg), (1. - pos + neg)))\n",
        "\n",
        "      A_norm = F.normalize(self.A, p=2, dim=-1)\n",
        "      tmp = torch.mm(A_norm, A_norm.t()) - self.identity_mat\n",
        "      orth_loss = torch.sqrt(torch.sum(tmp*tmp))\n",
        "\n",
        "      total_loss = loss + self.reg*orth_loss\n",
        "\n",
        "      return (total_loss, attn_wts_org, p_t)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVzxqX08C-XH"
      },
      "source": [
        "class customLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(customLoss,self).__init__()\n",
        "\n",
        "  def forward(self,x,y):\n",
        "    return x[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzD8epSxnQec"
      },
      "source": [
        "###Embedding matrix and Aspect matrix\n",
        "The Embedding matrix remains fixed during the training. The Aspect matrix is initialized with cluster centres in the embedding space and is learned during the training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE8H6xwNlESz",
        "outputId": "98ac7aea-751e-4a51-cb66-4d027fcbcb7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "emb_matrix=np.random.rand(VOCAB_SIZE, EMB_DIM)\n",
        "rare_words = {}\n",
        "\n",
        "for index, word in enumerate(vocab.itos):\n",
        "  try:\n",
        "    emb_matrix[index] = kv[word]\n",
        "  except KeyError:\n",
        "    rare_words[word] = index\n",
        "\n",
        "emb_matrix = np.asarray(emb_matrix)\n",
        "NORM_EMB_MATRIX = emb_matrix / np.linalg.norm(emb_matrix, axis=-1, keepdims=True)\n",
        "\n",
        "NORM_EMB_MATRIX = NORM_EMB_MATRIX.astype(np.float32)\n",
        "NORM_EMB_MATRIX[PAD_IDX] = np.zeros(300, dtype=np.float32)\n",
        "\n",
        "NORM_EMB_MATRIX.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqTfhWHGE3hy",
        "outputId": "5e106f63-59dd-49c9-8acb-64c07490de3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "km = KMeans(n_clusters=NUM_ASP)\n",
        "# km.fit(kv[kv.vocab])\n",
        "km.fit(emb_matrix)\n",
        "clusters = km.cluster_centers_\n",
        "\n",
        "# L2 normalization\n",
        "NORM_ASPECT_MATRIX = clusters / np.linalg.norm(clusters, axis=-1, keepdims=True)\n",
        "NORM_ASPECT_MATRIX = NORM_ASPECT_MATRIX.astype(np.float32)\n",
        "\n",
        "NORM_ASPECT_MATRIX.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O54Mg1ZJgQ8m",
        "outputId": "13912eac-e1ff-49dd-83fa-61fd62268cbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model_ABAE = ABAE(vocab_size=VOCAB_SIZE, emb_dim=EMB_DIM, norm_emb_matrix=NORM_EMB_MATRIX, norm_aspect_matrix=NORM_ASPECT_MATRIX, num_aspects=NUM_ASP, neg_size=20, reg=1)\n",
        "model_ABAE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ABAE(\n",
              "  (E): Embedding(17000, 300, padding_idx=1)\n",
              "  (L): Linear(in_features=300, out_features=14, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrGKSp5m8ZtY"
      },
      "source": [
        "class customLearner(Learner):\n",
        "  def __init__(self, data:DataBunch, model:nn.Module, **learn_kwargs):\n",
        "    metrics = []\n",
        "    super().__init__(data, model, metrics=metrics, **learn_kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-67jEzgTg0P9",
        "outputId": "4839a7af-1a0b-4a23-899e-75d452b8dd3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "learner = customLearner(data, model_ABAE)\n",
        "learner.loss_func = customLoss()\n",
        "\n",
        "learner.fit_one_cycle(10, 0.001, moms=(0.9,0.8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>579.117004</td>\n",
              "      <td>566.104370</td>\n",
              "      <td>00:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>474.116302</td>\n",
              "      <td>477.551117</td>\n",
              "      <td>00:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>481.123444</td>\n",
              "      <td>467.410919</td>\n",
              "      <td>00:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>459.277283</td>\n",
              "      <td>462.286163</td>\n",
              "      <td>00:46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>463.944977</td>\n",
              "      <td>459.196228</td>\n",
              "      <td>00:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>462.719025</td>\n",
              "      <td>457.464630</td>\n",
              "      <td>00:46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>458.775360</td>\n",
              "      <td>457.931641</td>\n",
              "      <td>00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>439.764069</td>\n",
              "      <td>456.123260</td>\n",
              "      <td>00:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>425.021332</td>\n",
              "      <td>455.682159</td>\n",
              "      <td>00:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>432.650513</td>\n",
              "      <td>455.163940</td>\n",
              "      <td>00:45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLaKS6T_J_qV"
      },
      "source": [
        "# learner.fit_one_cycle(2, 0.001, moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28SynWSws5__",
        "outputId": "d7d5ef8c-0493-4ca8-d6c0-f8835b0bbf76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "aspects = to_np(learner.model.A)\n",
        "topn = []\n",
        "for a in aspects:\n",
        "  topn.append(kv.most_similar(positive=[a], topn=10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLLj4p3DIazP",
        "outputId": "62bac3ed-11cd-4d3b-a188-a0e6d291bfe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "for top in topn:\n",
        "  print(top)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('dish', 0.5662596225738525), ('appetizer', 0.5110486745834351), ('appetizers-', 0.47879448533058167), ('entree', 0.46034032106399536), ('appetizer-', 0.4351925849914551), ('scallopine', 0.42037874460220337), ('remoulade', 0.4107510447502136), ('salad', 0.40592193603515625), ('sauted', 0.40525999665260315), ('vegetable', 0.4016492962837219)]\n",
            "[('visitng', 0.3520797789096832), ('anniversay', 0.3480328619480133), ('dinner', 0.33131587505340576), ('experience', 0.33064791560173035), ('overnight', 0.3254878520965576), ('lastnight', 0.3241574764251709), ('anniversery', 0.3226591944694519), ('experiences', 0.3219515085220337), ('annual', 0.31943073868751526), ('night', 0.3184662461280823)]\n",
            "[('food', 0.6341506242752075), ('service', 0.3252947926521301), ('meal', 0.3003639876842499), ('service--', 0.27895790338516235), ('unintrusive', 0.25507932901382446), ('meals', 0.24161140620708466), ('fodd', 0.24115429818630219), ('servic', 0.2389167845249176), ('food-', 0.2201651632785797), ('experiece', 0.2176593542098999)]\n",
            "[('sauceless', 0.25543686747550964), ('pepporoni', 0.2547736167907715), ('okonomiyaki', 0.24787120521068573), ('tomatoey', 0.24746209383010864), ('thickest', 0.24588266015052795), ('steack', 0.24316664040088654), ('sirlion', 0.2427699863910675), ('flakes', 0.24220027029514313), ('limp', 0.24211940169334412), ('reuben', 0.24164626002311707)]\n",
            "[('restaurant', 0.6293907165527344), ('place', 0.5188998579978943), ('resturant', 0.4281854033470154), ('resaurant', 0.42373231053352356), ('restuarant', 0.418386310338974), ('reastaurant', 0.40771839022636414), ('restauraunt', 0.40020012855529785), ('restraurant', 0.3939318358898163), ('restaurant--', 0.38096925616264343), ('restauarant', 0.374567449092865)]\n",
            "[('9:45pm', 0.46606698632240295), ('9:45', 0.44946154952049255), ('7:45pm', 0.42975741624832153), ('7:15pm', 0.42891043424606323), ('9:30pm', 0.4217360019683838), ('8:30pm', 0.4178946614265442), ('9:15', 0.41555607318878174), ('table', 0.41422343254089355), ('10:30pm', 0.41412776708602905), ('seat', 0.41335466504096985)]\n",
            "[('gauzy', 0.3838108479976654), ('curving', 0.3588832914829254), ('tapestries', 0.35597848892211914), ('tabletop', 0.3410515785217285), ('tabletops', 0.333462655544281), ('hewn', 0.32077112793922424), ('illuminated', 0.31761813163757324), ('decor', 0.31491127610206604), ('tableware', 0.3147594630718231), ('atmospheric', 0.31272053718566895)]\n",
            "[('pricetag', 0.35843971371650696), ('225', 0.33306658267974854), ('750', 0.32986995577812195), ('$', 0.31981903314590454), ('price', 0.31498217582702637), ('15-$20', 0.2929037809371948), ('59', 0.27989470958709717), ('350', 0.2739527225494385), ('20-$25', 0.27391308546066284), ('47', 0.2684483528137207)]\n",
            "[('great', 0.3204360604286194), ('kirin', 0.30432337522506714), ('mochas', 0.29121649265289307), ('dessert', 0.27965325117111206), ('69', 0.26728320121765137), ('perfect', 0.25908809900283813), ('coffees', 0.2590727210044861), ('kir', 0.2567858099937439), ('$', 0.24908548593521118), ('wonderful', 0.24835112690925598)]\n",
            "[('waiter', 0.5485945343971252), ('waitress', 0.49806249141693115), ('server', 0.4572405219078064), ('mngr', 0.440623939037323), ('manager', 0.4207194149494171), ('waittress', 0.416850745677948), ('waiteress', 0.3806969225406647), ('busboy', 0.3797916769981384), ('waitor', 0.37112200260162354), ('bartendress', 0.36575546860694885)]\n",
            "[('service', 0.7100303769111633), ('staff', 0.5143731832504272), ('servic', 0.48975953459739685), ('services', 0.47549793124198914), ('service--', 0.44695740938186646), ('waitstaff', 0.44626331329345703), ('service-', 0.42511165142059326), ('serviced', 0.4242081046104431), ('servce', 0.41233789920806885), ('waitstaffs', 0.3980735242366791)]\n",
            "[('food', 0.4089009761810303), ('time', 0.33616989850997925), ('fod', 0.2768291234970093), ('cuisine', 0.2762598693370819), ('menu', 0.2743099331855774), ('purity', 0.2699841558933258), ('cuisines', 0.26272809505462646), ('ingridients', 0.2491864711046219), ('stalwarts', 0.23500314354896545), ('pinnacle', 0.2322874814271927)]\n",
            "[('place', 0.5262218713760376), ('good', 0.46790361404418945), ('great', 0.34810009598731995), ('palce', 0.32611796259880066), (\"'cuz\", 0.29732298851013184), ('out-', 0.29209470748901367), ('place-', 0.28207334876060486), ('bucks', 0.28053492307662964), ('dont', 0.27827179431915283), ('wad', 0.27559295296669006)]\n",
            "[('good', 0.5577132105827332), ('great', 0.43757927417755127), ('excellent', 0.4096198081970215), ('excelllent', 0.33432912826538086), ('decent', 0.3251095712184906), ('wonderful', 0.30443984270095825), ('nice', 0.3015839457511902), ('fantastic', 0.29862409830093384), ('tasty', 0.28644704818725586), ('solid', 0.28638458251953125)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k582qBDxw6w0"
      },
      "source": [
        "gold_classes = ['Ambience', 'Anecdotes', 'Food', 'Miscellaneous', 'Price', 'Staff']\n",
        "infered_aspects = ['Food', 'Anecdotes', 'Miscellaneous', 'Food', 'Miscellaneous', 'Miscellaneous', 'Ambience', 'Price', 'Food',\n",
        "                   'Staff', 'Staff', 'Food', 'Miscellaneous', 'Miscellaneous']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igACN51cPcbk"
      },
      "source": [
        "##Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoxbJKGnCwyi"
      },
      "source": [
        "dl = learner.dl(DatasetType.Valid)\n",
        "ds = dl.dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIQu6cQsCK14"
      },
      "source": [
        "text = []\n",
        "res = []\n",
        "label = []\n",
        "for xb,yb in dl:\n",
        "  out = learner.model(xb)\n",
        "  for item in xb:\n",
        "    text.append(ds.reconstruct(item).text)\n",
        "  res.append(to_np(out[2]))\n",
        "  label.append(to_np(yb))\n",
        "\n",
        "res = np.concatenate(res)\n",
        "label = np.concatenate(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EHnSNm5s1Pn"
      },
      "source": [
        "final_df = pd.DataFrame.from_records(data=res, columns=infered_aspects)\n",
        "final_df['text'] = text\n",
        "final_df['label'] = label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjM28U5s63PF"
      },
      "source": [
        "final_df = final_df.groupby(level=0, axis=1).sum()\n",
        "final_df = final_df[['text', 'label']+gold_classes]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j11qNnequGSi"
      },
      "source": [
        "final_df.label = final_df.label.apply(lambda x: learner.data.classes[x])\n",
        "final_df['Num Labels'] = final_df.label.str.split().apply(len)\n",
        "result_df = final_df[final_df['Num Labels']==1].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbwIZkLJu4os",
        "outputId": "0908fc0e-2c6f-4773-d7c0-69e1687d2c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2843, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2ncvg4daQS0",
        "outputId": "9ca8f05b-36b4-4303-b121-8981ff047a78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "result_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>Ambience</th>\n",
              "      <th>Anecdotes</th>\n",
              "      <th>Food</th>\n",
              "      <th>Miscellaneous</th>\n",
              "      <th>Price</th>\n",
              "      <th>Staff</th>\n",
              "      <th>Num Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>get lobster roll $ opt codfish w pea risotto carrot reduction $ bread roll soft buttery lobster salad fresh taste have little generous meat bay fry season come vinegar dip ketchup available codfish decent fresh reduction especially interest find white flesh slightly bland skin season perfection</td>\n",
              "      <td>Food</td>\n",
              "      <td>0.022500</td>\n",
              "      <td>0.025690</td>\n",
              "      <td>0.360568</td>\n",
              "      <td>0.363904</td>\n",
              "      <td>0.137618</td>\n",
              "      <td>0.089720</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>consistantly great thin crisp crust inventive top combination smokiness believe new yorks old wood burn oven like naples wood pizza rest menu pizza place offer creative dish like prosciutto sushi brooklyn caviar brick oven shrimp salad huge pasta xxunk red sauced slop recieve pizza house</td>\n",
              "      <td>Food</td>\n",
              "      <td>0.074375</td>\n",
              "      <td>0.071492</td>\n",
              "      <td>0.157528</td>\n",
              "      <td>0.508011</td>\n",
              "      <td>0.088075</td>\n",
              "      <td>0.100519</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>finally get chance experience quality good food great food try get fort hamilton exit everyday life say go try pizzeria adorable kid sign astonish superb taste try far pizza chicken cutlet parm favorite chicken marsala correctly place perfect kinda surreal highly highly highly xxunk</td>\n",
              "      <td>Food</td>\n",
              "      <td>0.025195</td>\n",
              "      <td>0.039157</td>\n",
              "      <td>0.367865</td>\n",
              "      <td>0.455903</td>\n",
              "      <td>0.045772</td>\n",
              "      <td>0.066109</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pick scallion pancake fry vegetable juice special tasty xxunk chicken shredded squid family style personal favorite sichuan spicy soft shell crab xxunk fish hardcore sichuan food fan recommend american friend spicy</td>\n",
              "      <td>Food</td>\n",
              "      <td>0.025120</td>\n",
              "      <td>0.039072</td>\n",
              "      <td>0.368187</td>\n",
              "      <td>0.455948</td>\n",
              "      <td>0.045669</td>\n",
              "      <td>0.066004</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>warn reader portion size small especially appetizer plan eat intend order chef special taste menu prepare order pay appetizer dish person portion share main entree cold udon end meal</td>\n",
              "      <td>Food</td>\n",
              "      <td>0.047074</td>\n",
              "      <td>0.026770</td>\n",
              "      <td>0.342553</td>\n",
              "      <td>0.315097</td>\n",
              "      <td>0.113683</td>\n",
              "      <td>0.154824</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                      text  ... Num Labels\n",
              "0  get lobster roll $ opt codfish w pea risotto carrot reduction $ bread roll soft buttery lobster salad fresh taste have little generous meat bay fry season come vinegar dip ketchup available codfish decent fresh reduction especially interest find white flesh slightly bland skin season perfection  ...  1        \n",
              "1  consistantly great thin crisp crust inventive top combination smokiness believe new yorks old wood burn oven like naples wood pizza rest menu pizza place offer creative dish like prosciutto sushi brooklyn caviar brick oven shrimp salad huge pasta xxunk red sauced slop recieve pizza house         ...  1        \n",
              "2  finally get chance experience quality good food great food try get fort hamilton exit everyday life say go try pizzeria adorable kid sign astonish superb taste try far pizza chicken cutlet parm favorite chicken marsala correctly place perfect kinda surreal highly highly highly xxunk              ...  1        \n",
              "4  pick scallion pancake fry vegetable juice special tasty xxunk chicken shredded squid family style personal favorite sichuan spicy soft shell crab xxunk fish hardcore sichuan food fan recommend american friend spicy                                                                                   ...  1        \n",
              "5  warn reader portion size small especially appetizer plan eat intend order chef special taste menu prepare order pay appetizer dish person portion share main entree cold udon end meal                                                                                                                   ...  1        \n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H223rFWVuMw"
      },
      "source": [
        "lst = ['Ambience', 'Anecdotes', 'Food', 'Price', 'Staff']\n",
        "dct = {}\n",
        "for g in gold_classes:\n",
        "  dct[g] = g+'_raw'\n",
        "dct\n",
        "\n",
        "result_df = result_df.rename(columns=dct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvXx-fllQonq"
      },
      "source": [
        "threshold = 0.19\n",
        "col = 'Staff'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RpkDMYkbWob",
        "outputId": "285c1440-a559-4f3f-f959-02d6fa497267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "for g in lst:\n",
        "  result_df[g] = 0\n",
        "  result_df.loc[result_df[g+'_raw']>=threshold, g] = 1\n",
        "\n",
        "result_df['Miscellaneous'] = 1-result_df[lst].max(axis=1)\n",
        "\n",
        "result_df['y'] = 0\n",
        "result_df.loc[result_df.label==col, 'y']=1\n",
        "\n",
        "y_true = result_df.y.values\n",
        "y_pred = result_df[col].values\n",
        "\n",
        "print('Accuracy: ', accuracy_score(y_true, y_pred))\n",
        "print('F1 Score: ', f1_score(y_true, y_pred, average=\"macro\"))\n",
        "print('Precision: ', precision_score(y_true, y_pred, average=\"macro\"))\n",
        "print('Recall: ', recall_score(y_true, y_pred, average=\"macro\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.9215617305663032\n",
            "F1 Score:  0.8044842349572834\n",
            "Precision:  0.8330034256536212\n",
            "Recall:  0.7820369238348965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CrmDcrWKkFB"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wWVRgiFY5dL"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}